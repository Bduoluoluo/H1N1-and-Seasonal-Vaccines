{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class Node:\n",
    "    def __init__ (self, value, split=None):\n",
    "        self.value = value\n",
    "        self.split = split\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class CART:\n",
    "    def __init__ (self, epsilon=0.01):\n",
    "        self.epsilon = epsilon\n",
    "        self.tree = None\n",
    "        self.features = None\n",
    "    \n",
    "    # 基尼不纯度\n",
    "    def calc_gini (self, y):\n",
    "        gini = 0\n",
    "        for y_unique, y_cnt in zip(*np.unique(y, return_counts=True)):\n",
    "            prob = y_cnt / len(y)\n",
    "            gini += prob * (1 - prob)\n",
    "        return gini\n",
    "\n",
    "    # 特征条件下的基尼不纯度\n",
    "    def calc_cond_gini (self, X, y):\n",
    "        sorted_X = np.unique(np.sort(X, axis=0))\n",
    "        split_pos = (sorted_X[: -1] + sorted_X[1:]) / 2\n",
    "        best_gini = float(\"inf\")\n",
    "        best_split = None\n",
    "        for pos in split_pos:\n",
    "            lmask, rmask = X <= pos, X > pos\n",
    "            cond_gini = (sum(lmask) * self.calc_gini(y[lmask]) + sum(rmask) * self.calc_gini(y[rmask])) / len(y)\n",
    "            if (cond_gini < best_gini):\n",
    "                best_gini = cond_gini\n",
    "                best_split = pos\n",
    "        return best_gini, best_split\n",
    "\n",
    "    def build (self, X, y):\n",
    "        y_unique = np.unique(y)\n",
    "        if (len(y_unique) == 1):\n",
    "            return Node(value=y_unique[0])\n",
    "        if (X.shape[0] == 0):\n",
    "            return Node(value=0.5)\n",
    "        best_gini = float(\"inf\")\n",
    "        best_split = None\n",
    "        best_feature = None\n",
    "        for i in range(X.shape[1]):\n",
    "            gini, split = self.calc_cond_gini(X.iloc[:, i], y)\n",
    "            if (gini < best_gini):\n",
    "                best_gini = gini\n",
    "                best_split = split\n",
    "                best_feature = i\n",
    "        if (best_gini < self.epsilon):\n",
    "            return Node(value=np.mean(y))\n",
    "        tree = Node(value=self.features[best_feature], split=best_split)\n",
    "        lmask, rmask = X.iloc[:, best_feature] <= best_split, X.iloc[:, best_feature] > best_split\n",
    "        tree.left = self.build(X[lmask], y[lmask])\n",
    "        tree.right = self.build(X[rmask], y[rmask])\n",
    "        return tree\n",
    "\n",
    "    def fit (self, X, y):\n",
    "        self.features = list(X.columns)\n",
    "        self.tree = self.build(X, y)\n",
    "\n",
    "    def search (self, x):\n",
    "        root = self.tree\n",
    "        split = root.split\n",
    "        while split is not None:\n",
    "            index = self.features.index(root.value)\n",
    "            if (x[index] <= root.split):\n",
    "                root = root.left\n",
    "            else:\n",
    "                root = root.right\n",
    "            split = root.split\n",
    "        return root.value\n",
    "\n",
    "    def predict (self, X):\n",
    "        y = []\n",
    "        for x in X:\n",
    "            y.append(self.search(x))\n",
    "        return y\n",
    "    \n",
    "    def getMean (self, tree):\n",
    "        mean = 0\n",
    "        if (tree.left is not None):\n",
    "            mean += self.getMean(tree.left)\n",
    "        if (tree.right is not None):\n",
    "            mean += self.getMean(tree.right)\n",
    "        return mean / 2\n",
    "\n",
    "    # 剪枝\n",
    "    def prune (self, tree, X, y):\n",
    "        if (X.shape[0] == 0):\n",
    "            tree.value = self.getMean(tree)\n",
    "            tree.split = None\n",
    "            tree.left = None\n",
    "            tree.right = None\n",
    "            return tree\n",
    "        if (tree.split is None):\n",
    "            return tree\n",
    "        index = self.features.index(tree.value)\n",
    "        lmask, rmask = X.iloc[:, index] <= tree.split, X.iloc[:, index] > tree.split\n",
    "        tree.left = self.prune(tree.left, X[lmask], y[lmask])\n",
    "        tree.right = self.prune(tree.right, X[rmask], y[rmask])\n",
    "        if (tree.left.split is None and tree.right.split is None):\n",
    "            error_no_merge = np.sum(np.power(y[lmask] - tree.left.value, 2)) + np.sum(np.power(y[rmask] - tree.right.value, 2))\n",
    "            error_merge = np.sum(np.power(y - self.getMean(tree), 2))\n",
    "            if (error_merge < error_no_merge):\n",
    "                tree.value = self.getMean(tree)\n",
    "                tree.split = None\n",
    "                tree.left = None\n",
    "                tree.right = None\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./TrainData.csv\")\n",
    "\n",
    "X = train_data.drop(columns=[\"h1n1_vaccine\", \"seasonal_vaccine\"])\n",
    "y = train_data[[\"h1n1_vaccine\", \"seasonal_vaccine\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "y1_train, y2_train = y_train.iloc[:, 0], y_train.iloc[:, 1]\n",
    "y1_test, y2_test = y_test.iloc[:, 0], y_test.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对于 h1n1_vaccine 标签，其信息增益最大的特征为： doctor_recc_h1n1\n",
      "对于 seasonal_vaccine 标签，其信息增益最大的特征为： opinion_seas_vacc_effective_5.0\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "# 经验熵\n",
    "def calc_ent (datasets):\n",
    "    data_length = len(datasets)\n",
    "    label_count = {}\n",
    "    for i in range(data_length):\n",
    "        label = datasets[i][-1]\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 0\n",
    "        label_count[label] += 1\n",
    "    ent = -sum([(p / data_length) * log(p / data_length, 2) for p in label_count.values()])\n",
    "    return ent\n",
    "\n",
    "# 经验条件熵\n",
    "def cond_ent (datasets, axis = 0):\n",
    "    data_length = len(datasets)\n",
    "    feature_sets = {}\n",
    "    for i in range(data_length):\n",
    "        feature = datasets[i][axis]\n",
    "        if feature not in feature_sets:\n",
    "            feature_sets[feature] = []\n",
    "        feature_sets[feature].append(datasets[i])\n",
    "    cond_ent = sum([(len(p) / data_length) * calc_ent(p) for p in feature_sets.values()])\n",
    "    return cond_ent\n",
    "\n",
    "# 信息增益\n",
    "def info_gain (ent, cond_ent):\n",
    "    return ent - cond_ent\n",
    "    \n",
    "def info_gain_train (datasets):\n",
    "    count = len(datasets[0]) - 1\n",
    "    ent = calc_ent(datasets)\n",
    "    best_feature = []\n",
    "    for c in range(count):\n",
    "        c_info_gain = info_gain(ent, cond_ent(datasets, axis = c))\n",
    "        best_feature.append((c, c_info_gain))\n",
    "    best_ = max(best_feature, key = lambda x: x[-1])\n",
    "    return best_\n",
    "\n",
    "data_set_1 = pd.concat([X_train, y1_train], axis=1)\n",
    "data_set_2 = pd.concat([X_train, y2_train], axis=1)\n",
    "\n",
    "columns_name = [column for column in X]\n",
    "print(\"对于 h1n1_vaccine 标签，其信息增益最大的特征为：\", columns_name[info_gain_train(np.array(data_set_1))[0]])\n",
    "print(\"对于 seasonal_vaccine 标签，其信息增益最大的特征为：\", columns_name[info_gain_train(np.array(data_set_2))[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剪枝前 h1n1_vaccine: 0.6549834052439429\n",
      "剪枝后 h1n1_vaccine: 0.7217561400597411\n",
      "剪枝前 seasonal_vaccine: 0.7187384847347728\n",
      "剪枝后 h1n1_vaccine: 0.7881303885806883\n"
     ]
    }
   ],
   "source": [
    "model_1 = CART()\n",
    "model_1.fit(X_train, y1_train)\n",
    "y1_pre = model_1.predict(np.array(X_test))\n",
    "print(\"剪枝前 h1n1_vaccine:\", roc_auc_score(y1_test, y1_pre))\n",
    "model_1.prune(model_1.tree, X_test, y1_test)\n",
    "y1_pre = model_1.predict(np.array(X_test))\n",
    "print(\"剪枝后 h1n1_vaccine:\", roc_auc_score(y1_test, y1_pre))\n",
    "\n",
    "model_2 = CART()\n",
    "model_2.fit(X_train, y2_train)\n",
    "y2_pre = model_2.predict(np.array(X_test))\n",
    "print(\"剪枝前 seasonal_vaccine:\", roc_auc_score(y2_test, y2_pre))\n",
    "model_2.prune(model_2.tree, X_test, y2_test)\n",
    "y2_pre = model_2.predict(np.array(X_test))\n",
    "print(\"剪枝后 h1n1_vaccine:\", roc_auc_score(y2_test, y2_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv(\"./TestFeatures.csv\")\n",
    "id = np.array(test_features[\"respondent_id\"])\n",
    "X_features = np.array(test_features.drop(columns=[\"respondent_id\"]))\n",
    "\n",
    "y1_label = model_1.predict(X_features)\n",
    "y2_label = model_2.predict(X_features)\n",
    "\n",
    "output = pd.DataFrame({\"respondent_id\": id, \"h1n1_vaccine\": y1_label, \"seasonal_vaccine\": y2_label})\n",
    "output.to_csv(\"./submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
